[TOC]

# 面试题

- [x] TCP详细总结
  - [x] [参考](https://juejin.cn/post/6844904070889603085#heading-1)
- [x] TCP是怎么实现可靠传输的？
  - [x] 说了校验和、序列号机制解决乱序、确认重传机制解决丢失问题
  - [x] 三次连接和四次挥手也是可靠传输的保证。
- [x] TCP拥塞控制、区分流量控制和拥塞控制
- [x] ARP过程（工作的层次）
- [x] https为什么要用非对称加密和对称加密结合？
- [x] 非对称加密为什么比对称加密耗时？
- [x] dns协议原理？
  - [x] 工作过程？怎么配置的？
- [x] DHCP自动配置：ip地址、子网掩码、网关地址、dns服务器地址
- [x] cn和com分别是什么域名？级别怎么分的？
  - [x] cn是中国国内顶级域名，com是国际顶级域名，两者应该是同级的
- [x] dns的查询过程，迭代和递归分别是怎么做的？



# TCP状态时序图

- TCP中各个状态转换图？

  <img src="/Users/apple/Documents/work2022/C++ knowledge/picture/TCP通信时序图.png" alt="TCP通信时序图" style="zoom:67%;" />

  ​	 	**主动建立连接方**：**CLOSED** ---- 发送SYN后 ---- **SYN_SEND** ---- 收到对端ACK和SYN ---- **ESTABLISHED**；

  ​		**被动接收连接方**：**CLOSED** ---- **LISTEN** ---- 收到对端发送的SYN，发送SYN和ACK ---- **SYN_RECV** ----收到对端ACK ---- **ESTABLISHED**；

  ​		**主动断开连接方**：**ESTABLISHED** ---- 发送FIN后 ---- **FIN_WAIT1** ---- 收到对端发送的ACK后 ---- **FIN_WAIT2**（此时处于半关闭状态）---- 收到对端发送的FIN后并发送ACK ---- **TIME_WAIT** ---- 等待2MSL ---- **CLOSED**；

  ​		**被动接收断开连接方**：**ESTABLISHED** ---- 接收到对端SYN并发送ACK后 ---- **CLOSED_WAIT** ---- 发送SYN后 ---- **LAST_ACK** ---- 接收到对端ACK后 ---- **CLOSED**；

- **time_wait状态产生的原因？危害？如何避免？**

  - [原因详解](https://blog.csdn.net/huangyimo/article/details/81505558)

  - **原因1）**为实现TCP这种全双工连接的可靠释放

    ​		如果主动关闭一方（视为client）发送的**ACK**（4次挥手的最后一个包）在网络中丢失，由于TCP重传机制，被动关闭的一方会重发其**FIN**，在FIN到达client之前，client必须维护这条连接的状态。具体而言就是这条TCP连接对应的资源不能被立即释放或重新分配。

    ​		如果client不进入TIME_WAIT以维护其连接状态，当server重发的FIN到达时，client方**TCP传输层**会以**RST包**响应对方，这会被对方认为有错误发生。

  - **原因2）**为使旧的数据包在网络因过期而消失

    ​		假设TCP协议中不存在TIME_WAIT状态的限制，再假设当前有一条TCP连接：**(local_ip, local_port, remote_ip,remote_port)**，因为某些原因，我们先关闭，接着很快以相同的四元组建立一条新连接。由于TCP连接由四元组唯一标识，因此，在假设的情况中，TCP协议栈是无法区分前后两条TCP连接的不同的，在它看来，这根本就是同一条连接，中间先释放再建立的过程对其来说是“感知”不到的。

    ​		这样就可能发生这样的情况：**前一条TCP连接**由local peer发送的数据到达remote peer后，会被该remot peer的TCP传输层**当做当前TCP连接**的正常数据接收并向上传递至应用层（而事实上，这些旧数据到达remote peer前，旧连接已断开且一条由相同四元组构成的新TCP连接已建立，因此，这些旧数据是不应该被向上传递至应用层的），从而引起数据错乱进而导致各种无法预知的诡异现象。

    ​		 具体而言，local peer主动调用close后，此时的TCP连接进入TIME_WAIT状态，处于该状态下的TCP连接不能立即以同样的四元组建立新连接，即**主动关闭方**占用的**local port**在TIME_WAIT期间不能再被重新分配。由于TIME_WAIT状态持续时间为2MSL，这样保证了旧TCP连接双工链路中的旧数据包均因过期（超过MSL）而消失，此后，就可以用相同的四元组建立一条新连接而不会发生前后两次连接数据错乱的情况。

  - 避免：**端口复用**

    `int opt = 1; setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt));`



# 长连接、短连接、HTTP无状态、Keep-Alive

HTTP的长连接和短连接并不准确，**HTTP不是连接是请求**；

**TCP是连接，TCP才有长连接和短连接**；

HTTP协议说到底是应用层的协议，而TCP才是真正的传输层协议，只有负责传输的这一层才需要建立连接。

❗️❗️❗️HTTP协议是**无状态**的，指的是协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。也就是说，打开一个服务器上的网页和你之前打开这个服务器上的网页之间没有任何联系。

HTTP是一个**无状态的面向连接的协议**，无状态不代表HTTP不能保持TCP连接，更不能代表HTTP使用的是UDP协议（无连接）。❗️❗️❗️

**HTTP/1.0**中默认使用的是短连接；

**HTTP/1.1**起，默认使用长连接，以保持连接特性；

使用长连接的HTTP协议在**响应头**中加入 `Connection:Keep-alive` ；

**Keep-alive不会永久保持连接**，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接要客户端和服务端都支持长连接。

**TCP/IP详解**中提到的**TCP保活功能**主要是服务器端提供的。服务器应用希望知道客户端主机是否崩溃；

[TCP保活机制](https://blog.51cto.com/u_15346415/3674622)理解保活机制探测的几种状态

- 正常工作
- 崩溃或正在重启
- 崩溃后重启：原连接已失效，对方不认识探测报文，会响应重置报文段，RST。
- 对端正常，但网络异常

**HTTP的keep-alive**指的就是上面所说的长连接；

**TCP的keepalive**指的是长时间无数据交互时的一种保活机制；

- 长连接优缺点：

  **好处**是减少握手次数，不需要经常建立和关闭连接，节约资源（CPU、内存、网络带宽等）；

  因为减少了TCP请求，所以减少了网络的堵塞；

  减少了后续请求的响应时间；

  TCP慢启动：

  **坏处**就是会影响服务器端整体性能，太多连接一致占有，直接影响服务器的并发数

- 短连接优缺点：

  短连接对于服务器来说较为简单，存在的连接都是有用的连接，不需要额外的控制；

  但如果客户端连接频繁，会在tcp的建立和关闭上浪费时间。



# 半连接队列、全连接队列

[参考](https://www.cnblogs.com/xiaolincoding/p/12995358.html)

- 半连接队列：SYN队列

- 全连接队列：accept队列

  服务端收到客户端发起的 SYN 请求后，**内核会把该连接存储到半连接队列**，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，**内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。**

SYN洪泛（泛洪、Flood）攻击？

客户端恶意伪造IP并发送给服务端请求建立连接，使得半连接队列满，其他正常请求服务的得不到响应；

如何解决？

`netstat -n -p TCP | grep SYN_RECV` linux上使用命令查看处于半连接的个数

- 限制半连接流量和缩短SYN Timeout时间：

  当检测到大量的请求连接但是无ACK的情况是，服务器缩短SYN timeout时间，也就是服务器主动丢弃无响应应ACK的连接请求，从而缓解半连接队列被恶意占满的问题。

- Syn cookie：

  与传统TCP连接不同，服务器再接收到TCP SYN包并返回TCP SYN + ACK包时，并不需要对接下来可能收到的数据包进行资源的预留而是根据这个SYN包计算出一个cookie值。这个cookie作为将要返回的SYN ACK包的初始序列号。当客户端返回一个ACK包时，根据包头信息计算cookie，与返回的确认序列号进行对比，如果相同，则是一个正常连接，然后，分配资源，建立连接



# SYN、FIN为什么都需要消耗一个序列号？

TCP是面向连接的可靠传输的流式协议，序列号和确认号就是用来保证可靠传输的。

**TCP**是一个支持可靠数据传输的网络协议，怎么做到可靠传输？主要是看**确认**这个步骤来做到的，即**ACK**号。用**ACK**号来表达我这边已经收到了你传过来的内容，包含了**数据和命令**两种内容。

在可靠的TCP传输过程中，用于**建立和释放这个可靠通道的东西就是命令**。这两个过程都是需要双方主动参与和确认回复的，当一方想要开始一段可靠连接，并且给予了自己的相关数据后，另外一方，则需要对这一命令进行确认，确认只能通过确认号来做。这个事情在断开连接的时候也是一样的。

**TCP**除了**SYN**和**FIN**还有其它的标志，为什么他们不需要占用一个序列号呢？

首先，ACK就不用说了，它本身就是为了确认这个动作而生的，如果在给它一个序列号，就意味着还要给这一序列号进行ack，就会陷入无限循环中。**PUS、URG**是一个属性，一个附加在一段数据传输上的属性，它不属于命令或数据；**RST**比较特殊，它似乎是一个命令，但是基本上如果需要用这个命令的时候，TCP的可靠性也基本没有了，所以对这个命令进行确认已经无意义。



# TCP可靠传输->拥塞控制、滑动窗口、流量控制

[参考](https://segmentfault.com/a/1190000022944999)

**如何保证可靠传输：**

- 三次握手
- 四次挥手
- 校验和
- 序号、确认序号、超时重传
  - ARQ：停止等待ARQ：信道利用率低，等待时间长；但是简单
  - 连续ARQ：信道利用率高；但是连续数据包中间丢失需要发送方GBN（回退N步）
  - 连续ARQ下：确认丢失和确认迟到两种情况讨论
- 流量控制（接受窗口和发送窗口）、拥塞控制（拥塞窗口）
  - **拥塞控制是一个全局性的过程**，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，**流量控制往往是点对点通信量的控制，是个端到端的问题**。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。
  - TCP 发送方要维持一个**拥塞窗口(cwnd)**的状态变量。
  - 拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。
  - 发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个；
  - **慢开始、拥塞避免、快重传与快恢复** [参考](https://zhuanlan.zhihu.com/p/37379780)



# TCP粘包、拆包问题

- UDP是基于报文发送的，从UDP的帧结构可以看出，在UDP首部采用了16比特位来指示UDP数据报文的长度，因此在应用曾能很好的将不同的数据报文区分开；
- **原因**：
  - 应用程序写入的数据大于套接字缓冲区大小，这将会发生拆包；
  - 应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发生粘包；
  - 进行MSS（最大报文长度）大小的TCP分段，当TCP报文长度-TCP头部长度>MSS的时候将发生拆包；
  - 接收方法不及时读取套接字缓冲区数据，也发生粘包。
- **解决方法：在应用层实现**
  - 发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。
  - 发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。
  - 可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。如redis使用 `\r\n` 来区分；
- **什么时候不需要处理粘包现象**
  - 如果是**短连接**情况，无需考虑粘包情况
  - 如果发送方发送的多个分组本来就是同一个数据的不同部分，比如一个很大的文件被分成多个分组发送，这时，当然不需要处理粘包的现象；例如文件传输，只管发送就行，全盘接收存储即可；



# TSL/SSL PKI证书体系

- **HTTPS（Secure Hypertext Transfer Protocol）安全超文本传输协议**，是一个安全通信通道，它基于HTTP开发用于在客户计算机和服务器之间交换信息。它使用**安全套接字层（SSL）**进行信息交换，简单来说它是HTTP的安全版，**是使用TLS/SSL加密的HTTP协议**；
- **HTTPS**的主要作用就是：
  - 对数据进行加密，并建立一个信息安全通道，来保证传输过程中的数据安全；
  - 对网站服务器进行真实身份认证；
- 对比HTTP和HTTPS：
  - HTTPS标准端口443，HTTP标准端口80；
  - HTTPS基于传输层，HTTP基于应用层；？
  - HTTPS需要用到SSL证书，而HTTP不需要；
- HTTP协议采用明文传输信息，存在**信息窃听**、**信息篡改**和**信息劫持**的风险，而协议TLS/SSL具有**身份验证**、**信息加密**和**完整性校验**的功能，可以避免此类问题发生；

- **PKI：Public Key Infrastructure（公钥基础架构）**
- **数字证书**：是由权威的机构给服务端颁发，**CA**机构通过服务端提供的相关信息生成证书，证书中包含**服务器公钥**，**签署者数字签名（CA提供）**，**服务端相关信息（域名、组织信息等）**；
  - 服务端将公钥、组织信息、域名等信息发送给CA机构；
  - CA机构通过线上、线下多种手段验证申请者提供信息的真实性；
  - CA机构通过散列函数计算接受的明文信息生成**信息摘要**；CA机构通过自己的**私钥**对**信息摘要**加密生成签名；
  - 客户端像服务端发出请求时，服务端返回**证书文件**；
  - 客户端通过CA公布的**公钥**解密证书中的**签名**，再用**散列函数**计算得到**信息摘要**，对比两种信息，客户端可以知道公钥的真实性；
  - 客户端都内置CA证书了；
  - 谷歌浏览器上地址栏带🔒的表示是安全有证书的；
- TSL握手过程
  - [参考](https://juejin.cn/post/6895624327896432654)



# 浏览器地址栏输入一个url过程

- **url解析**：输入内容是否符合URL规则

  - **encodeURI、decondeURI**可以对中文、空格等编解码，适用于URL本身
  - **encodeURIComponent、decodeURIComponent**范围更广，会编码解码一些特殊字符如 `:/?=+@#$`,适用于给参数编码解码

- **缓存**

  [参考其中浏览器缓存](https://juejin.cn/post/6844903665631756295)

  **参考HTTP缓存节**

- **dns解析流程**

- **http协议先通过TCP三次握手**

- **https协议建立TLS安全通道连接**

- **发送HTTP请求**

- **接受HTTP响应**

- **HTTP状态码**

  - **1xx**：指示信息——表示请求已经接受，继续处理
    - `100 Continue` 一般在发送 `post` 请求时，已发送了 `http header` 之后服务端返回此信息，表示确认，之后发送具体参数信息。
  - **2xx**：成功
    - `200 OK` 正常返回信息
    - `201 Created` 请求成功并且服务器创建了新的资源
    - `202 Accepted` 服务器已接受请求，但尚未处理
  - **3xx**：重定向
    - `301 Moved Permanently` 永久重定向
    - `302 Found` 临时重定向
    - `303 See Other` 临时重定向，且总是使用 `GET` 请求新的 `URI`
    - `304 Not Modified` 请求内容未改动，走缓存
  - **4xx**：客户端错误
    - `400 Bad Request` 服务器无法理解请求格式
    - `401 Unauthorized` 请求未授权
    - `403 Forbidden` 禁止访问
    - `404 Not Found` 找不到与 `URI` 相匹配的资源
  - **5xx**：服务器错误。
    - `500 Internal Server Error` 服务器内部错误
    - `503 Service Unavailable` 服务器暂时无法处理请求



# HTTP2.0与1.1、1.0对比





# HTTP缓存

[参考其中缓存部分](https://juejin.cn/post/6844903665631756295)

- **强制缓存优先于协商缓存：**

- **强缓存（强制缓存）**：

  当浏览器向服务器发送请求时，服务器会将缓存规则放入HTTP响应报文的HTTP头中和请求结果一起返回给浏览器，控制强制缓存的字段分别是**Expires**和**Cache-Control**，其中**Cache-Control**比**Expires**优先级高，**两个同时存在时，Cache-Control优先级高**；

  **Expires** 是 **HTTP/1.0**控制网页缓存的字段，其值为服务器返回**该请求结果缓存的到期时间**，这里是绝对日期，如果客户端的时间小于 Expires 的值时，直接使用缓存结果；

  > Expires是HTTP/1.0的字段，现在浏览器默认使用**HTTP/1.1**，Expires已经被**Cache-Control**替代
  >
  > 在HTTP/1.1中，Cache-Control主要用于控制网页缓存，其主要取值为:
  >
  > - public ：所有内容都被缓存 (客户端和代理服务器都可缓存)
  > - **private**： 所有内容只有客户端可以缓存，Cache-Control的默认取值
  > - no-cache：客户端缓存内容，但是是否使用缓存则需要经过协商缓存来验证决定
  > - no-store：所有内容都不会被缓存，即不使用强制缓存，也不使用协商缓存
  > - **max-age=xxx (xxx is numeric)**：缓存内容将在xxx秒后失效，这里是相对值

- **协商缓存**

  - 协商缓存就是强制缓存失效后，浏览器携带缓存标识向服务器发起请求，由服务器根据**缓存标识**决定是否继续使用缓存的过程；

  - **协商缓存生效，返回304**：

    > **304状态码表示客户端发送附带条件（附带条件包括If-Match、If-Modified-Since；ETag、If-None-Match等字段）的请求时，服务器端允许请求访问资源，但未满足条件的情况。304状态码返回时，不包含任何响应的主体部分。**

  - **协商缓存失效，返回200和请求结果**

- **如何判断协商缓存是否失效**

  - 协商缓存的控制字段有 **Last-Modified /If-Modified-Since 和 Etag/If-None-Match**。 **Etag/If-None-Match的优先级比Last-Modified /If-Modified-Since 高**；

  - **Last-Modified /If-Modified-Since**

    > **Last-Modified**表示一个服务器上的资源的最后修改时间，资源可以是静态的或者动态的内容。**一般在第一次请求时服务器发给客户端的缓存标识**
    >
    > `last-modified: Fri, 20 Apr 2018 10:10:50 GMT`
    >
    > **If-Modified-Since**：客户端再次发送该请求时，携带上次请求返回的**Last-Modified**值，服务器收到该请求，发现 **If-Modified-Since字段**，**如果服务器资源的最后修改时间大于If-Modified-Since的值，则重新返回新资源，状态码为200，此时则表明协商缓存失效，之前的缓存不再使用。否则，返回304，资源没有被更新，协商缓存生效，继续使用浏览器缓存。**

  - **Etag/If-None-Match**

    > **Etag**：是服务器响应请求时，返回当前资源文件的唯一的编号；
    >
    > **If-None-Match**：客户端再次发起该请求时，携带上次请求返回的唯一编号，**服务器收到请求后，将If-None-Match的字段值与该资源在服务器上的Etag值做对比，一致则返回304，说明资源无更新，协商缓存生效，继续使用缓存文件，不一致说明资源已更新，重新返回资源文件，状态码为200**；

- 浏览器缓存分为**内存缓存(from memory cache)** 和**硬盘缓存(from disk cache)**:

  - **内存缓存(from memory cache)**：具有两个特点，分别是快速读取和时效性：

    > **快速读取**： 内存缓存会将编译解析后的文件，直接存入该进程的内存中，占据该进程一定的内部资源，以方便下次运行使用时的快速读取
    >
    > **时效性**：一旦进程关闭，则该进程的内存则会清空。

  - **硬盘缓存(from disk cache)**: 硬盘缓存则是直接将缓存写入硬盘文件中，读取缓存需要对该缓存存放的硬盘文件进行I/O操作，然后重新解析该缓存内容，读取复杂，速度比内存缓存慢。

  - **F5**，浏览器会绕过**本地缓存（强制缓存）**，但是**协商缓存**依旧有效

  - **Ctrl+F5强制刷新**，浏览器会绕过本地缓存和协商缓存，让服务器返回最新的资源
  
- **启发式缓存**：

  - 如果响应未显示**Expires**或**Cache-Control：max-age/s-maxage**，并且响应中不包含其他有关缓存的限制，缓存可以使用启发式方法计算新鲜度寿命；
  - 根据响应头部中的**Date**字段值减去**Last-Modified**字段值的结果的10%作为缓存时间；
  



# TCP的快速打开 TFO—理解它是在TCP握手是发送数据

[参考](https://blog.csdn.net/wyb_robin/article/details/107129338)

TCP建立连接需要三次握手，但是三次握手会导致传输效率下降，尤其是HTTP这种短连接的协议，虽然HTTP有keep-alive来让一些请求频繁的HTTP提高性能，避免了一些三次握手的次数。

但是还是希望能绕过三次握手提高效率，或者说**在三次握手的同时就把数据传输的事情给做了**，这就是**TCP Fast Open，简称TFO**。

TFO的目的是在**TCP层面**减少每次传输需要握手的耗时问题；HTTP长连接是在HTTP层面上做的；注意区分；

TFO第一个优化就是客户端在第三次发送数据时可以携带数据；

- 当客户端第一次连接服务端时，是没有Cookie的，所以会发送一个**空的Cookie**，意味着要请求Cookie；
- 服务端就会**将Cookie通过SYN+ACK的路径返回给客户端**，客户端保存后，将发送的数据以及三次握手的最后一步ACK同时发送给服务端；
- 当客户端断开连接，下一次请求同一个服务端的时候，会带上**之前存储的Cookie和要发送的数据，在SYN的路径上一起发送给服务端**；
- **每次握手的时候还同时发送了数据信息，将数据传输提前了。服务端只要验证了Cookie，就会将发送的数据接收，否则会丢弃并且再通过SYN+ACK路径返回一个新的Cookie，这种情况一般是Cookie过期导致的**；



# TCP、HTTP对头阻塞

- **TCP队头阻塞**

  TCP数据包是有序传输，中间一个数据包丢失，会等待该数据包重传，造成后面的数据包的阻塞。

- **HTTP队头阻塞**

  http队头阻塞和TCP队头阻塞完全不是一回事。

  http1.1采用长连接，可以在一个TCP请求上，发送多个http请求。

  有非管道化和管道化，两种方式（pipeline）。

  **非管道化**，完全串行执行，请求->响应->请求->响应...，后一个请求必须在前一个响应之后发送。

  **管道化**，请求可以并行发出，但是响应必须串行返回。后一个响应必须在前一个响应之后。原因是，没有序号标明顺序，只能**串行接收**。

  **管道化请求的致命弱点**:

  1. 会造成队头阻塞，前一个响应未及时返回，后面的响应被阻塞;
  2. 请求必须是**幂等请求**，不能修改资源。因为，意外中断时候，客户端需要把未收到响应的请求重发，非幂等请求，会造成资源破坏。
  3. **幂等请求**：一个HTTP 方法是幂等的，指的是同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。 幂等方法不应该具有副作用（统计用途除外）。 在正确实现的条件下， GET ， HEAD ， PUT 和 DELETE 等方法都是幂等的，而 POST 方法不是。 所有的safe 方法也都是幂等的。

  目前大部分浏览器和Web服务器都关闭了管道化，采用非管道化模式。

  解决方法：**HTTP2**使用一个域名单一TCP连接发送请求，请求包被二进制分帧，不同请求可以互相穿插，避免了HTTP层面的请求队头阻塞。但是不能避免TCP层面的队头阻塞。（HTTP2新特性）



# DNS域名解析过程

> 互联网都是通过URL来发布和请求资源的，而URL中的域名需要解析成IP地址才能与远程主机建立连接，如何将域名解析成IP地址就属于DNS解析的工作范畴；
>
> **DNS（Domain Name System）**是域名系统的英文缩写，是一种组织成域层次结构的计算机和网络服务命名系统，它用于TCP/IP网络，它所提供的服务是将主机名和域名转换为IP地址的工作

- **根域名服务器**

  最高层次的域名服务器，也为最重要的域名服务器；**所有的根域名服务器**（即不止一个）都知道所有的顶级域名服务器的域名和IP地址；

- **顶级域名服务器（TLD）**

  负责管理在改顶级域名服务器下注册的所有二级域名

- **权威域名服务器**

  一般你具体访问的域名就在这里

- **本地域名服务器（LDNS）**

  **实际上本地域名服务器不属于域名服务器的层次结构**，但是它对域名系统非常重要，当一台主机发出DNS查询请求时，这个查询请求报文首先是发送给本地域名服务器。每个**ISP（当地网络接入商）**都有一个本地域名服务器；

- **DNS域名解析过程**

  > - 检查浏览器缓存是否有这个域名对应的IP地址
  >
  > - 检查操作系统缓存中是否有这个域名对应的IP地址 `/etc/hosts`
  >
  > - 向本地服务器查询：
  >
  >   - **递归**：
  >
  >     **主机向本地域名服务器的查询一般都是采用递归查询**，所为递归查询就是：如果主机所访问的本地域名服务器不知道被查询域名的IP地址，那么本地域名就以DNS客户的身份，替代主机，向其他根域名服务器继续发出查询请求报文，而不是让主机自己进行下一步的查询。
  >
  >   - 迭代：
  >
  >     **本地域名服务器向根域名服务器的查询通常是采用迭代查询**。迭代查询就是：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的IP地址，要么告诉本地域名服务器下一步应当向哪一个域名服务器查询，然后让本地域名服务器进行后续的查询
  >
  > - 本地服务器向根服务器查询；
  >
  > - 根服务器返回给本地服务器一个所查询域的顶级服务器地址
  >
  > - （迭代下一轮）本地服务器再向返回的顶级域名服务器发送请求
  >
  > - 顶级服务器返回给本地服务器此域名对应的权威服务器
  >
  > - （迭代下一轮）本地服务器再向返回的权威务器发送请求
  >
  > - 权威服务器会查询存储的域名和IP的映射关系表并返回给本地服务器
  >
  > - 本地在返回给请求的主机（递归返回）
  
- **顶级域名**

  - `com` 公司
  - `org` 非盈利组织
  - `net` 网络组织
  - `cn`、`jp`、`uk` 和国家相关
  

### DNS如何配置？



# 对称加密和非对称加密

- **对称加密**
  - DES、AES
  - 信息加密解密都是通过一个密钥进行
  - 加密解密快：**算法主要的运算是位运算**
- **非对称加密**：
  - RSA
  - 加密和解密使用不同的密钥；公钥加密的信息，只有私钥才能解密；私钥加密的信息，只有公钥才能解密；
  - 加密解密速度慢：**算法涉及大数乘法，大数模运算**
- **HTTP为何采用对称和非对称结合的方式**：



# ARP和RARP

- **ARP**

  - 为IP地址和对应的硬件地址之间提供映射；

  - ARP是解决**同一个局域网**上的主机或路由器的IP地址和硬件地址的映射问题的；

  - 原理：

    - ARP发送一份称为**ARP请求**的**以太网数据帧**给以太网上每个主机（广播）；
    - 本局域网上的所有主机上运行的**ARP进程**都收到此ARP请求分组；
    - 目的主机的ARP层收到广播报文后，向源主机发送**ARP响应分组**，并写入自己的硬件地址。其他主机收到广播报文后丢弃；

  - ARP高速缓存：

    每个主机都有一个ARP高速缓存，存放最近IP地址到硬件地址之间的映射记录。

    可以使用**arp命令**来查看和修改缓存记录，**使用arp命令添加的映射记录是永久的，没有超时时间**。

    ARP把保存在高速缓存中的每一个映射地址都设置生存时间（10~20分钟），凡是超过生存时间的记录就从高速缓存中删除掉。

- **ARP四种典型应用情况：**

  - 发送方是主机，要把IP数据报发送到**本网络上的另一个主机**。这时用ARP找到目的主机的硬件地址。
  - 发送方是主机，要把IP数据报发送到**另一个网络上的一个主机**。这时用ARP找到**本网络上的一个路由器**的硬件地址，剩下的工作由这个路由器完成。
  - 发送方是**路由器**，要把IP数据报转发到**本网络上的一个主机**。这时用这时用ARP找到目的主机的硬件地址。
  - 发送方是**路由器**，要把IP数据报转发到**另一个网络上的一个主机**。这时用ARP找到**本网络上的一个路由器**的硬件地址。剩下的工作由这个路由器完成。

- **RARP**

  - 发送主机发送一个**本地的RARP广播**，在此广播包中，声明自己的MAC地址并且请求任何收到此请求的**RARP服务器**分配一个IP地址；
  - **本地网段上**的RARP服务器收到此请求后，检查其RARP列表，查找该MAC地址对应的IP地址；
  - 如果存在，RARP服务器就给源主机发送一个响应数据包并将此IP地址提供给对方主机使用；如果不存在，RARP服务器对此不做任何的响应；
  -  源主机收到从RARP服务器的响应信息，就利用得到的IP地址进行通讯；如果一直没有收到RARP服务器的响应信息，表示初始化失败。
  - 现在的**DHCP协议**已经包含RARP协议的功能，所以很少再单独使用RARP协议了；

- **免费ARP**

  - 发送主机请求的**目的IP地址字段的值**就是发送主机本身的IP地址；发送主机不希望有别的主机使用和自己相同的IP，避免IP冲突；



# 为什么有了IP地址还需要MAC地址？

- **角度1**：只有IP，没有MAC。网卡的实现上极其困难。

  > 如果没有MAC地址，网卡就需要解读网络层协议头的地址信息，而每一种网络层的地址又都差不多，这增加了以太网卡的实现复杂度。而网卡有了MAC地址，就可以不依赖于任何网络层协议，可以独立判断一个以太帧是否接收（依据MAC地址匹配），这样大大简化了网卡的实现。即使有更多的网络层协议，网卡也无需太多改变。
  >
  > **思想：分层，内部实现无需知晓上层或下层协议字段。**

- **角度2**：只有MAC，没有IP。网卡的实现上极其困难。

  > 如果只使用MAC地址的话，**路由器**就需要记住每个MAC地址所在的子网是哪一个，而世界上有2的48次方个MAC地址，这就意味着即使我们给每个 MAC 地址只留 1 字节的储存空间，每个路由器也需要 256 TB 的内存！这显然是不可能实现的。

- **角度3**：只有IP，没有MAC。IP地址的局限。

  > IP地址是要设备上线以后，才能根据他进入了哪个子网来分配的，在设备还没有IP地址的时候（或者分配IP地址的过程中），还需要用MAC地址来区分不同的设备，并根据MAC地址通信。



# VLAN两种模式

- **access**
- **trunk**



# DHCP（动态主机配置协议）

- 配置哪些信息
- 如何配置



# NAT（网络地址转换）

































