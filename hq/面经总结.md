# 面经总结

## 专业技能

### C++语法

#### 1. 多态

- **概念：**基类指针可以按照基类的方式来做事，也可以按照派生类的方式来做事，它有**多种形态**，或者说有多种表现方式，我们将这种现象称为**多态（Polymorphism）**。多态的实现机制为**虚函数**；

- **虚函数的作用是允许在派生类中重新定义与基类同名的函数，并且可以通过基类指针或引用来访问基类和派生类的同名函数**。

  方法是在基类中为同名函数添加关键字**virtual**了；

- **实现：**

  - 多态的实现机制为**虚函数**；
  - C++实现虚函数的原理是**虚函数表+虚表指针**；
  - **当一个类里存在虚函数时，编译器会为类创建一个虚函数表**，**虚函数表**是一个**数组**，数组的元素存放的是类中**虚函数的地址**。同时**为每个类的对象添加一个隐藏成员，该隐藏成员保存了指向该虚函数表的指针。该隐藏成员占据该对象的内存布局的最前端**。所以虚函数表只有一份，而有多少个对象，就对应多少个虚函数表指针。

#### 2. 内联函数和宏函数的区别

- **宏定义不是函数，但是使用起来像函数。**预处理器用复制宏代码的方式代替函数的调用，省去了函数压栈退栈过程，提高了效率；而**内联函数本质上是一个函数，内联函数一般用于函数体的代码比较简单的函数**，不能包含复杂的控制语句，并且内联函数本身不能直接调用自身；
- 宏函数是在**预编译**的时候把所有的宏名用宏体来替换，简单的说就是字符串替换 ；而内联函数则是在**编译**的时候进行代码插入，编译器会在每处调用内联函数的地方直接把内联函数的内容展开，这样可以省去函数的调用的开销，提高效率；
- **宏定义是没有类型检查的，无论对还是错都是直接替换**；而**内联函数在编译的时候会进行类型的检查，内联函数满足函数的性质**，比如有返回值、参数列表等。

#### 3. 内存对齐

- **原因：**
  - CPU每次寻址都需要消耗时间的，如果一个数据一次取不完就要取多次。比如int类型的变量占4个字节，假设在内存中没有对齐(**所谓对齐，指的是内存中数据的首地址是CPU单次获取数据大小的整数倍**)，存放在0x00000003 - 0x00000006处(**0x00000003不是4的整数倍**)。那么每次取4字节(32位宽总线)的CPU第一次取到[0x00000000 - 0x00000003]，只得到变量a的1/4数据，进而需要进行第二次取数[0x00000004 - 0x00000007]，为了得到int类型的一个变量，却需要两次访问内存，并且还需要拼接处理，**性能较低**。
  - 有些CPU(ARM架构的)在内存非对齐的情况下，执行二进制代码会崩溃，因为不是所有的硬件平台都能访问任意地址上的任意数据的。倘若代码移植到其他不支持的平台上，就**不具有可移植性**。
- **内存对齐规则（编译器负责）：**
  - **编译器提供手动指定对齐值的关键字 #pragma pack(N)，可以手动设置对齐的字节数，**记为N。若没有手动指定，那么编译器就会默认将成员变量中最大的类型字节数设置为对齐值，记作m；
  - **整体对齐值**：首先计算对齐单位 n = min{N,m}，然后整体对齐后的字节数应该为n的倍数，不够的在最后面填补占位；
  - **成员对齐值**：首个成员的偏置地址offset为0。假定该成员的类型占字节数 j，那么本成员的偏移地址offset：min{n, j}的整数倍。

#### 4. C++与Java区别

- Java中不存在指针。Java的引用是功能弱化的指针，只能做“调用所指对象的方法”的操作；
- Java单根继承，所有对象都继承自Object。并且提供接口机制。C++支持多继承；
- C++支持运算符重载，Java则是通过重写基类方法；
- Java是完全面向对象的，所有方法都必须写在类中。C++兼容C语言，支持面向过程编程；
- C++需要程序员自己管理内存，Java则有垃圾回收机制；
- Java是半编译半解释的，先编译成字节码，然后在Java虚拟机中进行解释执行。相对于C++这种直接编译成机器码的语言，执行速度较慢，但跨平台支持度好。

### C++现代编程思想

#### 1. RAII手法

- **RAII**（资源取得时机便是初始化时机）是一种**“以对象管理资源”**的思想，可以**避免资源泄露**；
- **在管理对象的构造函数中获得资源并在析构函数中释放资源，不论控制流如何离开区块，一旦管理对象离开作用域被销毁，其析构函数会被自动调用，确保资源随之释放；**
- RAII的**例子**：智能指针**shared_ptr**，**Lock的实现**等；
- 普遍的**RAII class copying行为**：
  - **抑制copying**：如果复制动作对RAII class并不合理，就应该禁止它：**将copying操作声明为private**；
  - **施行引用计数法**：如果希望保有资源，直到它的最后一个使用者被销毁：**通常只要内含一个shared_ptr成员变量即可**。

#### 2. 类型转换

- **const_cast<T>()**：通常被用来**将对象的常量性转除**。它也是**唯一有此能力的C++-style转型操作符**；
- **dynamic_cast<T>()**：主要用来执行**“安全向下转型”**，也就是**用来决定某对象是否归属继承体系中的某个类型**。它是**唯一无法由旧式语法执行的动作**，也是**唯一可能耗费重大运行成本的转型动作**；
- **reinterpret_cast<T>()**：用来执行**低级转型**，实际动作（及结果）可能取决于编译器，这也表示它**不可移植**。例如将一个pointer to int转型为一个int。**这一类转型在低级代码以外很少见**；
- **static_cast<T>()**：用来**强迫隐式转换**，例如将**non-const对象转为const对象**，或将**int转为double**等等。它也可以用来执行上述多种转换的反向转换，例如将**void*指针转为typed指针**，将**pointer-to-base转为pointer-to-derived**。但它**无法将const转为non-const——这个只有const-cast才办得到**。

#### 3. 异常处理

- 异常提供了一种转移程序控制权的方式。C++ 异常处理涉及到三个关键字：**try、catch、throw**；
- 可以通过继承和重载 **exception** 类来定义新的异常。

#### 4. 内存分配

- **new和malloc的区别：**在于new会**多一步调用构造函数的过程**，而底层内存的分配还是通过调用malloc来实现的；
- **new：**调用**operator new分配空间**，通过（可看作）**placement new调用构造函数**；
- **operator new：**可重载到类里：Foo::operator new()，也可重载全局（比较少用）::operator new()，内部是调用malloc()；
- **placement new：**可通过此函数调用类的构造函数 new(foo)Foo(构造函数参数)，可被重载（比较少用，string中用到）。

#### 5. C11新特性

- **Lambda表达式**：

  - ```c++
    [capture](parameters)->return-type {body}
    ```

- **自动类型推导auto和decltype：**

  - **auto**用于类型声明，可以自动推导类型；
  - **操作符decltype**可以用于在一个表达式中”俘获“到其结果的类型。

- **统一的初始化语法**：统一使用**大括号**进行初始化；

- **default和delete：**

  - **=default：**用于**指示编译器生成该函数的默认实现**；
  - **=delete：**用于**实现对象的noncopyable**，**对拷贝构造函数和赋值构造函数禁止即可**。

- **nullptr：用于取代NULL。**因为NULL就是字面值0，而nullptr则是void*，如果用NULL的话遇到函数重载就会有问题；

- **右值引用：用于实现move语义。**当要复制的对象是”临时对象“时，不需要整个复制，只需要”窃取“其内部成员即可；

- **新的智能指针类和强制类型转换**：弃用了auto_ptr。

  

### STL

#### 1. 容器总结

|                             容器                             |   底层数据结构    |                        时间复杂度                         | 有无序 | 可不可重复 |                             其他                             |
| :----------------------------------------------------------: | :---------------: | :-------------------------------------------------------: | :----: | :--------: | :----------------------------------------------------------: |
| [array](https://github.com/huihut/interview/tree/master/STL#array) |       数组        |                       随机读改 O(1)                       |  无序  |   可重复   |                         支持随机访问                         |
| [vector](https://github.com/huihut/interview/tree/master/STL#vector) |       数组        | 随机读改、尾部插入、尾部删除 O(1) 头部插入、头部删除 O(n) |  无序  |   可重复   |                         支持随机访问                         |
| [deque](https://github.com/huihut/interview/tree/master/STL#deque) |     双端队列      |                  头尾插入、头尾删除 O(1)                  |  无序  |   可重复   | 一个中央控制器 + 多个缓冲区，支持首尾快速增删，支持随机访问  |
| [forward_list](https://github.com/huihut/interview/tree/master/STL#forward_list) |     单向链表      |                      插入、删除 O(1)                      |  无序  |   可重复   |                        不支持随机访问                        |
| [list](https://github.com/huihut/interview/tree/master/STL#list) |     双向链表      |                      插入、删除 O(1)                      |  无序  |   可重复   |                        不支持随机访问                        |
| [stack](https://github.com/huihut/interview/tree/master/STL#stack) |   deque / list    |                  顶部插入、顶部删除 O(1)                  |  无序  |   可重复   | deque 或 list 封闭头端开口，不用 vector 的原因应该是容量大小有限制，扩容耗时 |
| [queue](https://github.com/huihut/interview/tree/master/STL#queue) |   deque / list    |                  尾部插入、头部删除 O(1)                  |  无序  |   可重复   | deque 或 list 封闭头端开口，不用 vector 的原因应该是容量大小有限制，扩容耗时 |
| [priority_queue](https://github.com/huihut/interview/tree/master/STL#priority_queue) | vector + max-heap |                    插入、删除 O(log2n)                    |  有序  |   可重复   |                   vector容器+heap处理规则                    |
| [set](https://github.com/huihut/interview/tree/master/STL#set) |      红黑树       |                 插入、删除、查找 O(log2n)                 |  有序  |  不可重复  |                                                              |
| [multiset](https://github.com/huihut/interview/tree/master/STL#multiset) |      红黑树       |                 插入、删除、查找 O(log2n)                 |  有序  |   可重复   |                                                              |
| [map](https://github.com/huihut/interview/tree/master/STL#map) |      红黑树       |                 插入、删除、查找 O(log2n)                 |  有序  |  不可重复  |                                                              |
| [multimap](https://github.com/huihut/interview/tree/master/STL#multimap) |      红黑树       |                 插入、删除、查找 O(log2n)                 |  有序  |   可重复   |                                                              |
| [unordered_set](https://github.com/huihut/interview/tree/master/STL#unordered_set) |      哈希表       |              插入、删除、查找 O(1) 最差 O(n)              |  无序  |  不可重复  |                                                              |
| [unordered_multiset](https://github.com/huihut/interview/tree/master/STL#unordered_multiset) |      哈希表       |              插入、删除、查找 O(1) 最差 O(n)              |  无序  |   可重复   |                                                              |
| [unordered_map](https://github.com/huihut/interview/tree/master/STL#unordered_map) |      哈希表       |              插入、删除、查找 O(1) 最差 O(n)              |  无序  |  不可重复  |                                                              |
| [unordered_multimap](https://github.com/huihut/interview/tree/master/STL#unordered_multimap) |      哈希表       |              插入、删除、查找 O(1) 最差 O(n)              |  无序  |   可重复   |                                                              |

#### 2. 迭代器失效问题总结

- **vector迭代器失效情况**：
  - 当执行**erase**方法时，**指向删除节点及之后的全部迭代器失效**；
  - 当执行**push_back**方法时，**end操作返回的迭代器肯定失效**；
  - 当执行**插入（insert、push_back）**方法时，如果**底层发生扩容**了，就需要转移整个容器，此时**迭代器全部失效**；
  - 当执行**insert**方法时，如果**底层没有发生扩容**，则指向**插入位置之前的元素的迭代器仍然有效**，但指向**插入位置之后元素的迭代器全部失效**。
  - **解决方法：调用insert和erase后会返回更新后的迭代器，利用该返回的迭代器替换原有迭代器进行++**。
- **关联式容器迭代器失效情况**：
  - 对于map, set,multimap,multiset等，**删除当前的iterator，仅会使当前的iterator失效**，**只要在erase时，递增当前iterator即可**；
  - 因为map之类的容器使用了**红黑树来实现，插入、删除一个结点不会对其他结点造成影响**。erase迭代器只是被删元素的迭代器失效。但是**因为返回值为void，所以要采用erase(iter++)的方式删除迭代器**。
- **迭代器失效时不能执行++操作**。

#### 3. 智能指针

- **shared_ptr**：

  - 共享智能指针，**多个智能指针可以指向相同的对象，使用控制块管理引用计数，当计数器等于0时，资源会被释放**。可以传入unique_ptr,weak_ptr来构造，也可用new构造；
  - **支持定制型删除器（custom deleter）**，可**防范 Cross-DLL 问题**（对象在动态链接库（DLL）中被 new 创建，却在另一个 DLL 内被 delete 销毁）、**自动解除互斥锁**；

- ##### weak_ptr：

  - **weak_ptr 允许你共享但不拥有某对象，一旦最末一个拥有该对象的智能指针失去了所有权，任何 weak_ptr 都会自动成空（empty）**。因此，在 default 和 copy 构造函数之外，weak_ptr 只提供 “接受一个 shared_ptr” 的构造函数；
  - **可打破环状引用（两个其实已经没有被使用的对象彼此互指，使之看似还在 “被使用” 的状态）的问题**。

- ##### unique_ptr：

  - unique_ptr 是一种在异常时可以帮助避免资源泄漏的智能指针。**采用独占式拥有，意味着可以确保一个对象和其相应的资源同一时间只被一个 pointer 拥有。一旦被销毁或开始拥有另一个对象，先前拥有的那个对象就会被销毁，其任何相应资源亦会被释放**；
  - **unique_ptr 用于取代 auto_ptr**。

- ##### auto_ptr 与 unique_ptr 比较：

  - auto_ptr 可以赋值拷贝，复制拷贝后所有权转移；unqiue_ptr 无拷贝赋值语义，但实现了`move` 语义；
  - auto_ptr 对象不能管理数组（析构调用 `delete`），unique_ptr 可以管理数组（析构调用 `delete[]` ）。



### 数据结构与算法

#### 1. 排序总结

| 排序算法                                                     | 平均时间复杂度 | 最差时间复杂度 | 空间复杂度 | 数据对象稳定性       |
| ------------------------------------------------------------ | -------------- | -------------- | ---------- | -------------------- |
| [冒泡排序](https://github.com/huihut/interview/blob/master/Algorithm/BubbleSort.h) | O(n2)          | O(n2)          | O(1)       | 稳定                 |
| [选择排序](https://github.com/huihut/interview/blob/master/Algorithm/SelectionSort.h) | O(n2)          | O(n2)          | O(1)       | 数组不稳定、链表稳定 |
| [插入排序](https://github.com/huihut/interview/blob/master/Algorithm/InsertSort.h) | O(n2)          | O(n2)          | O(1)       | 稳定                 |
| [快速排序](https://github.com/huihut/interview/blob/master/Algorithm/QuickSort.h) | O(n*log2n)     | O(n2)          | O(log2n)   | 不稳定               |
| [堆排序](https://github.com/huihut/interview/blob/master/Algorithm/HeapSort.cpp) | O(n*log2n)     | O(n*log2n)     | O(1)       | 不稳定               |
| [归并排序](https://github.com/huihut/interview/blob/master/Algorithm/MergeSort.h) | O(n*log2n)     | O(n*log2n)     | O(n)       | 稳定                 |
| [希尔排序](https://github.com/huihut/interview/blob/master/Algorithm/ShellSort.h) | O(n*log2n)     | O(n2)          | O(1)       | 不稳定               |
| [计数排序](https://github.com/huihut/interview/blob/master/Algorithm/CountSort.cpp) | O(n+m)         | O(n+m)         | O(n+m)     | 稳定                 |
| [桶排序](https://github.com/huihut/interview/blob/master/Algorithm/BucketSort.cpp) | O(n)           | O(n)           | O(m)       | 稳定                 |
| [基数排序](https://github.com/huihut/interview/blob/master/Algorithm/RadixSort.h) | O(k*n)         | O(n2)          |            | 稳定                 |

#### 2. 红黑树和AVL树的区别

- **红黑树放弃了追求完全平衡，追求大致平衡（两子树高度相差不大于一倍），在与平衡二叉树的时间复杂度相差不大的情况下，保证每次插入最多只需要三次旋转就能达到平衡，实现起来也更为简单；**



### 计算机网络

#### 1. TCP概述

- **TCP（Transmission Control Protocol，传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议，其传输的单位是报文段。**

- **特征：**

  - **面向连接；**
  - **只能点对点（一对一）通信；**
  - **可靠交互；**
  - **全双工通信；**
  - **面向字节流。**

- **TCP如何保证可靠传输：**

  - **确认和超时重传；**
  - **数据合理分片和排序；**
  - **流量控制；**
  - **拥塞控制；**
  - **数据校验。**

- **TCP头部：**

  ![TCP头部](/Users/apple/Documents/work2022/hq/面经图片/TCP头部.png)

#### 2. TCP与UDP的区别

- **TCP 面向连接，UDP 是无连接的；**
- **TCP 提供可靠的服务，也就是说，通过 TCP 连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP 尽最大努力交付，即不保证可靠交付；**
- TCP 的逻辑通信信道是全双工的可靠信道；UDP 则是不可靠信道；
- **每一条 TCP 连接只能是点到点的；UDP 支持一对一，一对多，多对一和多对多的交互通信；**
- **TCP 面向字节流（可能出现黏包问题），实际上是 TCP 把数据看成一连串无结构的字节流；UDP 是面向报文的（不会出现黏包问题）；**
- **UDP 没有拥塞控制**，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 IP 电话，实时视频会议等）；
- **TCP 首部开销20字节；UDP 的首部开销小，只有 8 个字节。**

#### 3. TCP黏包问题

- **原因：**TCP 是一个**面向字节流**的传输服务（UDP 基于报文的），“流” 意味着 TCP 所传输的**数据是没有边界**的。所以可能会出现两个数据包黏在一起的情况。
- **解决：**
  - **发送定长包**。如果每个消息的大小都是一样的，那么在接收对等方只要累计接收数据，直到数据等于一个定长的数值就将它作为一个消息。
  - **包头中存包体长度**。包头是定长的 4 个字节，说明了包体的长度。接收对等方先接收包头长度，依据包头长度来接收包体。
  - **在数据包之间设置边界，如添加特殊符号 `\r\n` 标记。FTP 协议正是这么做的。但问题在于如果数据正文中也含有 `\r\n`，则会误判为消息的边界。**
  - 使用更加复杂的**应用层协议**。

#### 4. TCP拥塞控制

- **概念：**拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。
- **方法：**
  - **慢开始；**
  - **拥塞避免；**
  - **快重传；**
  - **快恢复。**
- ![TCP拥塞控制流程图](/Users/apple/Documents/work2022/hq/面经图片/TCP拥塞控制流程图.png)

#### 5. TCP建立连接

- ![TCP建立连接图](/Users/apple/Documents/work2022/hq/面经图片/TCP建立连接图.png)
- **三次握手过程描述：**
  - **客户端发送 SYN 给服务器，说明客户端请求建立连接；**
  - **服务端收到客户端发的 SYN，并回复 SYN+ACK 给客户端（同意建立连接）；**
  - **客户端收到服务端的 SYN+ACK 后，回复 ACK 给服务端（表示客户端收到了服务端发的同意报文）；**
  - **服务端收到客户端的 ACK，连接已建立，可以数据传输。**
- **为什么是三次握手？**
  - **四次握手：**因为**服务端的ACK和SYN可以合并成一次**，所以只需要三次握手，可提高连接的速度与效率；
  - **二次握手：服务端无法确定客户端是否已经接受到了自己的SYN，如果这个SYN丢失了，服务端和客户端就无法成功确认彼此的初始序列号。**

#### 6. TCP释放连接

- ![TCP释放连接图](/Users/apple/Documents/work2022/hq/面经图片/TCP释放连接图.png)
- **四次挥手过程描述：**
  - 客户端发送 FIN 给服务器，说明客户端不必发送数据给服务器了（请求释放从客户端到服务器的连接）；
  - **服务器接收到客户端发的 FIN，并回复 ACK 给客户端（同意释放从客户端到服务器的连接）；**
  - **客户端收到服务端回复的 ACK，此时从客户端到服务器的连接已释放（但服务端到客户端的连接还未释放，并且客户端还可以接收数据）；**
  - **服务端继续发送之前没发完的数据给客户端；**
  - **服务端发送 FIN+ACK 给客户端，说明服务端发送完了数据（请求释放从服务端到客户端的连接，就算没收到客户端的回复，过段时间也会自动释放）；**
  - **客户端收到服务端的 FIN+ACK，并回复 ACK 给客户端（同意释放从服务端到客户端的连接）；**
  - **服务端收到客户端的 ACK 后，释放从服务端到客户端的连接。**
- **TCP 为什么要进行四次挥手？ / 为什么 TCP 建立连接需要三次，而释放连接则需要四次？**
  - **因为 TCP 是全双工模式，客户端请求关闭连接后，客户端向服务端的连接关闭（一二次挥手），服务端继续传输之前没传完的数据给客户端（数据传输），服务端向客户端的连接关闭（三四次挥手）**。**所以 TCP 释放连接时服务器的 ACK 和 FIN 是分开发送的（中间隔着数据传输）**，而 TCP 建立连接时服务器的 ACK 和 SYN 是一起发送的（第二次握手），所以 TCP 建立连接需要三次，而释放连接则需要四次。
- **为什么 TCP 连接时可以 ACK 和 SYN 一起发送，而释放时则 ACK 和 FIN 分开发送呢？（ACK 和 FIN 分开是指第二次和第三次挥手）**
  - **因为客户端请求释放时，服务器可能还有数据需要传输给客户端，因此服务端要先响应客户端 FIN 请求（服务端发送 ACK），然后数据传输，传输完成后，服务端再提出 FIN 请求（服务端发送 FIN）；而连接时则没有中间的数据传输，因此连接时可以 ACK 和 SYN 一起发送。**
- **为什么客户端释放最后需要 TIME-WAIT 等待 2MSL 呢？**
  - **为了保证客户端发送的最后一个 ACK 报文能够到达服务端。**若未成功到达，则服务端超时重传 FIN+ACK 报文段，客户端再重传 ACK，并重新计时。
  - **防止已失效的连接请求报文段出现在本连接中。**TIME-WAIT 持续 2MSL 可使本连接持续的时间内所产生的所有报文段都从网络中消失，这样可使下次连接中不会出现旧的连接报文段。

#### 7. TCP有限状态机

![TCP有限状态机](/Users/apple/Documents/work2022/hq/面经图片/TCP有限状态机.png)

#### 8. HTTPS

- 利用**TLS协议**保证数据的安全性，在**TCP三次握手后进行TLS握手**；
- **握手过程**：
  - ![TLS握手过程](/Users/apple/Documents/work2022/hq/面经图片/TLS握手过程.jpg)
  - **client1**：TLS版本号+所支持加密套件列表+希望使用的TLS选项；
  - **Server1**：选择一个客户端的加密套件+自己的公钥+自己的证书+希望使用的TLS选项+（要求客户端证书）；
  - **Client2**：(自己的证书)+使用服务器公钥和协商的加密套件加密一个对称秘钥（自己生成的一个随机值）；
  - **Server2**：使用私钥解密出对称秘钥（随机值）后，发送加密的Finish消息，表明完成握手。
- **加密过程**：
  - ![HTTPS加密过程](/Users/apple/Documents/work2022/hq/面经图片/HTTPS加密过程.png)
- **加密方式**：对称加密算法加密数据+非对称加密算法交换密钥+数字证书验证身份。
  - **非对称加密+对称加密**：因为非对称加密耗时，所以**HTTPS采用非对称加密+对称加密结合的方式，来尽量减少非对称加密的次数**。该过程中非对称加密、解密各只需用一次即可：
    - 某网站服务器拥有用于非对称加密的公钥A、私钥A’；
    - 浏览器向网站服务器请求，服务器把公钥A明文给传输浏览器；
    - 浏览器随机生成一个用于对称加密的密钥X，用公钥A加密后传给服务器；
    - 服务器拿到后用私钥A’解密得到密钥X；
    - 这样双方就都拥有密钥X了，且别人无法知道它。之后双方所有数据都通过密钥X加密解密即可。
  - **中间人攻击问题**：**（根本原因是浏览器无法确认收到的公钥是不是网站自己的）**
    - 某网站有用于非对称加密的公钥A、私钥A’。
    - 浏览器向网站服务器请求，服务器把公钥A明文给传输浏览器。
    - **中间人劫持到公钥A，保存下来，把数据包中的公钥A替换成自己伪造的公钥B（它当然也拥有公钥B对应的私钥B’）**。
    - 浏览器生成一个用于对称加密的密钥X，用**公钥B**（浏览器无法得知公钥被替换了）加密后传给服务器。
    - **中间人劫持后用私钥B’解密得到密钥X，再用公钥A加密后传给服务器**。
    - 服务器拿到后用私钥A’解密得到密钥X。
  - **数字证书**：
    - 网站在使用HTTPS前，需要向**CA机构**申领一份**数字证书**，数字证书里含有证书持有者信息、公钥信息等。服务器把证书传输给浏览器，浏览器从证书里获取公钥就行了，证书就如身份证，证明“该公钥对应该网站”。而这里又有一个显而易见的问题，“**证书本身的传输过程中，如何防止被篡改”**？即如何证明证书本身的真实性？
    - 我们**把证书原本的内容生成一份“签名”，比对证书内容和签名是否一致就能判别是否被篡改**。这就是数字证书的“防伪技术”，这里的“签名”就叫**数字签名**。
    - 数字签名制作流程：
      - CA机构拥有非对称加密的私钥和公钥；
      - CA机构对证书明文数据T进行hash；
      - 对hash后的值用私钥加密，得到数字签名S。
    - 浏览器验证流程：
      - 拿到证书，得到明文T，签名S。
      - 用CA机构的公钥对S解密（由于是浏览器信任的机构，所以浏览器保有它的公钥。详情见下文），得到S’。
      - 用证书里指明的hash算法对明文T进行hash得到T’。
      - 显然通过以上步骤，T’应当等于S‘，除非明文或签名被篡改。所以此时比较S’是否等于T’，等于则表明证书可信。
- **每次进行HTTPS请求时都必须在SSL/TLS层进行握手传输密钥吗**？
  - **服务器会为每个浏览器维护一个session ID，在TLS握手阶段传给浏览器**，浏览器生成好密钥传给服务器后，服务器会把该密钥存到相应的session ID下，之后浏览器每次请求都会携带session ID，服务器会根据session ID找到相应的密钥并进行解密加密操作，这样就不必每次重新制作、传输密钥了。
- **加密算法**：HTTPS一般使用的加密与HASH算法如下：
  - 非对称加密算法：RSA，DSA/DSS
  - 对称加密算法：AES，RC4，3DES
  - HASH算法：MD5，SHA1，SHA256

### 网络编程

#### 1. 三组I/O复用函数的比较

- |                系统调用                |                            select                            |                             poll                             |                            Epoll                             |
  | :------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
  |                事件集合                | 用户通过3个参数分别传入感兴趣的可读、可写及异常等事件，内核通过对这些参数的在线修改来反馈其中的就绪时间。这使得用户每次调用select都要重置这3个参数 | 统一处理所有事件类型，因此只需一个事件集参数。用户通过pollfd.events传入感兴趣的事件，内核通过修改pollfd.revents反馈其中就绪的事件 | 内核通过一个事件表直接管理用户感兴趣的所有事件。因此每次调用epoll_wait时，无须反复传入用户感兴趣的事件。epoll_wait系统调用的参数events仅用来反馈就绪的事件 |
  | 应用程序索引就绪文件描述符的时间复杂度 |                             O(n)                             |                             O(n)                             |                             O(1)                             |
  |          最大支持文件描述符数          |                       一般有最大值限制                       |                            65535                             |                            65535                             |
  |                工作模式                |                              LT                              |                              LT                              |                        支持ET高效模式                        |
  |           内核实现和工作效率           |       采用轮询方式来检测就绪事件，算法时间复杂度为O(n)       |       采用轮询方式来检测就绪事件，算法时间复杂度为O(n)       |       采用回调方式来检测就绪事件，算法时间复杂度为O(1)       |

- **select理解**：用户代码中自旋实现所有阻塞socket的监听，但是每次判断socket是否产生数据，都涉及到用户态到内核态的切换。于是提出了select：将fd_set传入内核态，由内核判断是否有数据返回；并且之前只能使用自旋来时刻的去判断socket列表中是否有数据达到。而select是使用了一个等待队列，让线程在没有资源时park，当有数据到达时唤醒select线程，去处理socket。

  - 当进程A执行到创建socket的语句时，操作系统会创建一个由文件系统管理的socket对象。这个socket对象包含了发送缓冲区、接收缓冲区、等待队列等成员。等待队列指向所有需要等待该socket事件的进程；
  - 当程序执行到recv时，操作系统会将进程A从工作队列移动到该socket的等待队列中。当socket接收到数据后，操作系统将该socket等待队列上的进程重新放回到工作队列，该进程变成运行状态，继续执行代码。也由于socket的接收缓冲区已经有了数据，recv可以返回接收到的数据。

- **epoll理解**:epoll不会让每个 socket的等待队列都添加进程A，而是在等待队列，添加 eventPoll对象的引用。当socket就绪时，中断程序会操作eventPoll，在eventPoll中的就绪列表(rdlist)，添加socket。这样的话，进程A只需要不断循环遍历rdlist，从而获取就绪的socket。从代码来看每次执行到epoll_wait，其实都是去遍历 rdlist。如果rdlist为空，那么就阻塞进程。当有socket处于就绪状态，也是发中断信号，再调用对应的中断程序。此时中断程序，会把socket加到rdlist，然后唤醒进程。进程再去遍历rdlist，获取到就socket。

  - O(1)是因为epoll的回调机制，在执行epoll_ctl时，除了把socket放到对应的红黑树上之外，还会给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪rdlist链表里。所以，当一个socket上有数据到了，内核除了把网卡上的数据copy到内存中，还会把该socket插入到准备就绪链链表里。

#### 2. 两种高效的事件处理模式

- **Reactor模式**：**要求主线程（I/O处理单元）只负责监听文件描述上是否有事件发生**，有的话就立即将该事件通知工作线程（逻辑单元）。**除此之外，主线程不做任何其他实质性的工作。读写数据，接受新的连接，以及处理客户请求均在工作线程中完成**；
- **Proactor模式**：**将所有的I/O操作都交给主线程和内核来处理，工作线程仅仅负责业务逻辑**；

- **Reactor 是非阻塞同步网络模式，感知的是就绪可读写事件**。在每次感知到有事件发生（比如可读就绪事件）后，就需要应用进程主动调用 read 方法来完成数据的读取，也就是要应用进程主动将 socket 接收缓存中的数据读到应用进程内存中，这个过程是同步的，读取完数据后应用进程才能处理数据。
- **Proactor 是异步网络模式， 感知的是已完成的读写事件**。在发起异步读写请求时，需要传入数据缓冲区的地址（用来存放结果数据）等信息，这样系统内核才可以自动帮我们把数据的读写工作完成，这里的读写工作全程由操作系统来做，并不需要像 Reactor 那样还需要应用进程主动发起 read/write 来读写数据，操作系统完成读写工作后，就会通知应用进程直接处理数据。
- 因此，**Reactor 可以理解为「来了事件操作系统通知应用进程，让应用进程来处理」**，而 **Proactor 可以理解为「来了事件操作系统来处理，处理完再通知应用进程」**。这里的「事件」就是有新连接、有数据可读、有数据可写。
- 无论是 Reactor，还是 Proactor，都是一种基于「事件分发」的网络编程模式，区别在于 **Reactor 模式是基于「待完成」的 I/O 事件，而 Proactor 模式则是基于「已完成」的 I/O 事件**。
- **Reactor 模式的工作流程**：
  1. 主线程往 epoll 内核事件表中注册socket上的读就绪事件;
  2. 主线程调用 epoll_wait 等待 socket 上有数据可读;
  3. 当 socket 上有数据可读时，epoll_wait 通知主线程，主线程则将 socket 可读事件放入请求队列;
  4. 睡眠在请求队列上的某个工作线程被唤醒，它从 socket 读取数据，并处理客户请求，然后往 epoll 内核事件表中注册该 socket 上的写就绪事件;
  5. 主线程调用 epoll_wait 等待 socket 可写;
  6. 当 socket 可写时，epoll_wait 通知主线程，主线程将 socket 可写事件放入请求队列;
  7. 睡眠在请求队列上的某个工作线程（工作线程从请求队列读取事件后，根据事件的类型来决定如何处理它，没有必要区分读工作线程和写工作线程）被唤醒，它往 socket 上写入服务器处理客户请求的结果。
- **Procator 模式的工作流程**：
  1. 主线程调用 aio_read 向内核注册 socket 上的读完成事件，并告诉内核用户缓冲区的位置，以及读操作完成时如何通知应用程序（可以用信号）;
  2. 主线程继续处理其他逻辑;
  3. 当 socket 上的读数据被读入用户缓冲区后，内核向应用进程发送一个信号，已通知应用程序数据已经可用;
  4. 应用进程预先定义好的信号处理函数选择一个工作线程来处理处理客户请求，工作线程处理完客户请求之后，调用 aio_write 向内核注册 socket 的完成写事件，并告诉内核用户写缓冲区的位置，以及操作完成时如何通知应用程序（可以用信号）;
  5. 主线程继续处理其他逻辑;
  6. 当用户缓冲区的数据被写入 socket 之后，内核将向应用程序发送一个信号，已通知应用程序数据已经发送完毕;
  7. 应用程序预先定义好的信号处理函数选择一个工作线程来做善后处理，比如决定是否关闭 socket。
- **模拟 Proactor 模式**：（目前操作系统对异步IO的支持并非特别完善，更多的是采用IO多路复用模型模拟异步IO的方式）
  1. 主线程往 epoll 内核事件表上注册socket上的读就绪;
  2. 主线程调用 epoll_wait 等待 socket 上有数据可读;
  3. 当 socket 上有数据可读时，epoll_wait 通知主线程，主线程从 socket 上循环读取数据，直到没有更多数据可读，然后将读取到的数据封装成一个请求对象并插入到请求队列;
  4. 睡眠在请求队列上的某个工作线程被唤醒，他获得请求对象并处理客户请求，然后往 epoll 内核事件表中注册 socket 上的写就绪;
  5. 主线程调用 epoll_wait 等待 socket 可写;
  6. 当 socket 可写时，epoll_wait 通知主线程，主线程往 socket 上写入服务器处理客户请求结果;

### 数据库

#### 1. 引擎

- **MyISAM和InnoDB的区别**：
  - **InnoDB 支持事务，MyISAM 不支持**；
  - InnoDB 支持外键，而 MyISAM 不支持；
  - **InnoDB 是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高；MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针，主键索引和辅助索引是独立的**；
  - Innodb 不支持全文索引，而 MyISAM 支持全文索引，查询效率上 MyISAM 要高；
  - InnoDB 不保存表的具体行数，MyISAM 用一个变量保存了整个表的行数；
  - **MyISAM 采用表级锁(table-level locking)；InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁**。
- **MySQL执行查询的过程：**
  - 客户端通过 TCP 连接**发送连接请求**到 MySQL 连接器，连接器会对该请求**进行权限验证及连接资源分配**；
  - **查缓存**（当判断缓存是否命中时，MySQL 不会进行解析查询语句，而是直接使用 SQL 语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，例如空格、注解等都会导致缓存的不命中。）；
  - **语法分析**（判断SQL 语法是否写错了），把语句给到预处理器，检查数据表和数据列是否存在，解析别名看是否存在歧义；
  - **交给执行器，将数据保存到结果集中，同时会逐步将数据缓存到查询缓存中，最终将结果集返回给客户端**。

#### 2. 事务

- **概念：**事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。
- **事务的四个特征：**
  - **原子性**。事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做 ；
  - **一致性**。事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统 运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是 不一致的状态；
  - **隔离性**。一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰；
  - **持续性**。也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。
- **事务的实现原理：**
  - 事务是基于**重做日志文件(redo log)**和**回滚日志(undo log)**实现的；
  - 每提交一个事务必须先将该事务的所有日志写入到重做日志文件(redo log)进行持久化，数据库就可以通过重做日志来保证事务的原子性和持久性；
  - 每当有修改事务时，还会产生 undo log，如果需要回滚，则根据 undo log 的反向语句进行逻辑操作，比如 insert 一条记录就 delete 一条记录。**undo log 主要实现数据库的一致性**。
- **隔离级别：**
  - **Read Uncommitted（读未提交）** ：在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）；
  - **Read Committed（读提交）**： 这是大多数数据库系统的默认隔离级别（但不是 MySQL 默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的 commit，所以同一 select 可能返回不同结果；
  - **Repeatable Read（可重复读）**： 这是 MySQL 的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）；
  - **Serializable（可串行化）**： 通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争；
  - **MySQL 默认采用的 REPEATABLE_READ隔离级别**。
- **事务隔离的实现**：基于**锁机制**和**并发调度**。其中**并发调度使用的是MVVC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性**。

#### 3. MVCC

- **概念：**
  - 早期数据库系统，只有读读之间可以并发，读写，写读，写写都要阻塞。**引入多版本之后，只有写写之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了Innodb的并发度**；
  - **多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制**，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 **这样在读操作不用阻塞写操作，写操作不用阻塞读操作的同时，避免了脏读和不可重复读**。
- **实现：**
  - 在InnoDB中，**每行记录实际上都包含了两个隐藏字段：事务id(trx_id)和回滚指针(roll_pointer)**：
    - **trx_id**：事务id。**每次修改某行记录时，都会把该事务的事务id赋值给trx_id隐藏列**；
    - **roll_pointer**：回滚指针。**每次修改某行记录时，都会把undo日志地址赋值给roll_pointer隐藏列**；
    - 由于每次变动都会先把undo日志记录下来，并用roll_pointer指向undo日志地址。因此可以认为，**对该条记录的修改日志串联起来就形成了一个版本链，版本链的头节点就是当前记录最新的值**。
  - 如果数据库隔离级别是未提交读（READ UNCOMMITTED），那么读取版本链中最新版本的记录即可。如果是是串行化（SERIALIZABLE），事务之间是加锁执行的，不存在读不一致的问题。但是**如果是已提交读（READ COMMITTED）或者可重复读（REPEATABLE READ），就需要遍历版本链中的每一条记录，判断该条记录是否对当前事务可见，直到找到为止(遍历完还没找到就说明记录不存在)**。**InnoDB通过ReadView（一致性视图）实现了这个功能**。
  - **ReadView（一致性视图）的规则：**
    - 事务隔离时**读**的规则：
      - **对于未提交的版本，不可见**；
      - **对于已提交的版本，如果在视图创建前提交，可见**；
      - **对于已提交的版本，如果在视图创建后提交，不可见**。
    - 事务隔离时**写**的规则：
      - 采取**先“读”再写**，“读”是**当前读**，即**当前最新版本的值**。
  - **读提交和可重复读的实现区别：两者生成ReadView的时机不同。**
    - **读提交在每次读取数据前都会生成一个ReadView**，这样就能保证每次都能读到其它事务已提交的数据。
    - **可重复读只在第一次读取数据时生成一个ReadView**，这样就能保证后续读取的结果完全一致。

#### 4. 日志

- **binlog（二进制日志）**：
  - **概念**：binlog 用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。binlog是mysql的逻辑日志，并且由 Server层进行记录，使用任何存储引擎的 mysql数据库都会记录 binlog日志。
  - **使用场景：**
    - **主从复制** ：在 Master 端开启 binlog ，然后将 binlog发送到各个 Slave 端， Slave 端重放 binlog 从而达到主从数据一致；
    - **数据恢复** ：通过使用 mysqlbinlog 工具来恢复数据。
  - **日志格式：**
    - **statement：** 基于 SQL 语句的模式，某些语句和函数如 UUID, LOAD DATA INFILE 等在复制过程可能导致数据不一致甚至出错；
    - **row：** 基于行的模式，记录的是行的变化，很安全。但是 binlog 会比其他两种模式大很多，在一些大表中清除大量数据时在 binlog 中会生成很多条语句，可能导致从库延迟变大；
    - **mixed：** 混合模式，根据语句来选用是 statement 还是 row 模式。
- **redo log（事务日志）**：
  - **为什么需要redo log：**为了**实现事务的持久性**（只要事务提交成功，那么对数据库做的修改就被永久保存下来了）。
    - 事务的持久性可以通过每次提交事务时，将该事务涉及修改的数据页全部刷新到磁盘中，但**这样会有严重的性能问题，并且不具备crash-safe**：
      - 因为 Innodb 是**以页为单位进行磁盘交互的，而一个事务很可能只修改一个数据页里面的几个字节**，这个时候将完整的数据页刷到磁盘的话，太浪费资源了；
      - 一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用**随机IO写入性能太差**；
      - 对内存中的数据页写入磁盘时，**可能会因crash而丢失数据**。
    - 因此 mysql 设计了 redo log ， 具体来说就是只记录事务对数据页做了哪些修改，这样就能完美地解决性能问题了(相对而言**文件更小并且是顺序IO)，并且具备crash-safe**。
  - **redo log和binlog的区别：**
    - ![redo log和binlog的区别](/Users/apple/Desktop/leeZH/SELF/工作/C++面经/面经图片/redo log和binlog的区别.png)
    - binlog 日志只用于归档，**只依靠 binlog 是没有 crash-safe 能力的**。**但只有 redo log 也不行，因为 redo log 是 InnoDB特有的，且日志上的记录落盘后会被覆盖掉**。因此需要 binlog和 redo log二者同时记录，才能保证当数据库发生宕机重启时，数据不会丢失。
- **undo log（事务日志）：**
  - **为什么需要undo log**：为了**实现事务的原子性**（指对数据库的一系列操作，要么全部成功，要么全部失败，不可能出现部分成功的情况）；
  - **概念**：**undo log主要记录了数据的逻辑变化**，比如一条 INSERT 语句，对应一条DELETE 的 undo log ，对于每个 UPDATE 语句，对应一条相反的 UPDATE 的 undo log ，**这样在发生错误时，就能回滚到事务之前的数据状态**；
  -  **undo log 也是 MVCC(多版本并发控制)实现的关键**。

#### 5. 锁

- **锁的形式**：事务并发访问同一数据资源的情况主要就分为**读-读、写-写和读-写三种**。
  - **读-读**：即并发事务同时访问同一行数据记录。由于两个事务都进行只读操作，不会对记录造成任何影响，因此**并发读完全允许**；
  - **读-写**：即一个事务进行读取操作，另一个进行写入操作。这种情况下可能会产生脏读、不可重复读、幻读。**最好的方案是读操作利用多版本并发控制（MVCC），写操作进行加锁**；
  - **写-写**：即并发事务同时修改同一行数据记录。这种情况下可能导致脏写问题，这是任何情况下都不允许发生的，因此只能通过加锁实现，也就是**当一个事务需要对某行记录进行修改时，首先会先给这条记录加锁，如果加锁成功则继续执行，否则就排队等待，事务执行完成或回滚会自动释放锁（锁的二阶段协议）**。
- **锁的分类**：为了实现读-读之间不受影响，并且写-写、读-写之间能够相互阻塞，**Mysql使用了读写锁的思路进行实现，具体来说分为共享锁（读锁）和互斥锁（写锁）**。
  - **共享锁（读锁）**：在事务要读取一条记录时，需要先获取该记录的读锁。**读锁可以在同一时刻被多个事务同时持有**。（可以用select ...... lock in share mode;的方式手工加上一把读锁）；
  - **互斥锁（写锁）**：在事务要改动一条记录时，需要先获取该记录的写锁。**写锁在同一时刻最多只能被一个事务持有**。写锁的加锁方式有两种，第一种是自动加锁，**在对数据进行增删改的时候，都会默认加上一个写锁**（还有一种是手工加锁，用FOR UPDATE给一行数据加上一个写锁）；
  - **注意**：如果一个事务已经持有了某行记录的读锁，另一个事务是无法为这行记录加上写锁的，反之亦然。
  - **意向锁**：
    - **意向锁是由数据库自己维护的**，一般来说，当给一行数据加上共享锁之前，数据库会自动在这张表上面加一个**意向共享锁**；当我们给一行数据加上互斥锁之前，数据库会自动在这张表上面加一个**意向互斥锁**；
    - **意向锁可以认为是读锁和写锁在数据表上的标识，通过意向锁可以快速判断表中是否有记录被上锁，从而避免通过遍历的方式来查看表中有没有记录被上锁，提升加锁效率**。
- **锁的粒度**：按锁作用的数据范围进行分类的话，锁可以分为行级锁和表级锁。
  - **表级锁**：作用在整张数据表上，锁的粒度比较大。
    - InnoDB中的表级锁主要包括表级别的**意向共享锁**和**意向互斥锁**以及**自增锁(AUTO-INC锁)**。
  - **行级锁**：行级锁作用在记录上。
    - **InnoDB的行锁，是通过锁住索引来实现的，如果加锁查询的时候没有使用过索引，会将整个聚簇索引都锁住，相当于锁表；**
    - **根据锁定范围的不同**，行锁可以使用**记录锁**、**间隙锁**和**临键锁**的方式实现。
    - **MySQL默认行锁类型是临键锁。当使用唯一性索引，等值查询匹配到一条记录的时候，临键锁会退化成记录锁；没有匹配到任何记录的时候，退化成间隙锁**。
- **表级锁的应用场景**：**对于InnoDB表，在绝大部分情况下都应该使用行级锁**，因为事务和行锁往往是我们之所以选择InnoDB表的理由。**但在个另特殊事务中，也可以考虑使用表级锁**。
  - **事务需要更新大部分或全部数据，表又比较大**，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高该事务的执行速度；
  - **事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚**。这种情况也可以考虑一次性锁定事务涉及的表，从而避免死锁、减少数据库因事务回滚带来的开销。
  - 当然，应用中这两种事务不能太多，否则，就应该考虑使用ＭyISAＭ表。
- **数据库死锁**：
  - 在InnoDB中，除单个SQL组成的事务外，锁是逐步获得的，这就决定了InnoDB发生死锁是可能的；
  - **发生死锁后，InnoDB一般都能自动检测到，并使一个事务释放锁并退回，另一个事务获得锁，继续完成事务**。**但在涉及外部锁，或涉及锁的情况下，InnoDB并不能完全自动检测到死锁，这需要通过设置锁等待超时参数innodb_lock_wait_timeout来解决**。需要说明的是，这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获取所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖垮数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。
  - 如果出现死锁，可以用SHOW INNODB STATUS命令来确定最后一个死锁产生的原因和改进措施。

#### 6. 幻读

- **前提条件**：InnoDB引擎，可重复读隔离级别，使用**当前读**时；
- **表现**：一个事务(同一个read view)在前后两次查询同一范围的时候，后一次查询看到了前一次查询没有看到的行。**两点需要说明**：
  - 在可重复读隔离级别下，普通查询是快照读，是不会看到别的事务插入的数据的，幻读只在**当前读**下才会出现；
  - 幻读专指**新插入的行**，读到原本存在行的更新结果不算。因为**当前读**的作用就是能读到所有已经提交记录的最新值。
- **幻读的影响**：
  - 会造成一个事务中先产生的锁，无法锁住后加入的满足条件的行。
  - 产生数据一致性问题，在一个事务中，先对符合条件的目标行做变更，而在事务提交前有新的符合目标条件的行加入。这样通过binlog恢复的数据是会将所有符合条件的目标行都进行变更的。
- **幻读产生的原因**：
  - 行锁只能锁住行，即使把所有的行记录都上锁，也阻止不了新插入的记录。
- 如何解决幻读：
  - 将两行记录间的空隙加上锁，阻止新记录的插入：这个锁称为**间隙锁**。
  - 间隙锁与间隙锁之间没有冲突关系。跟间隙锁存在冲突关系的，是**往这个间隙中插入一个记录**这个操作。

### 设计模式

#### 1. 单例模式

- **概念：**单例 Singleton 是设计模式的一种，其特点是只提供**唯一**一个类的实例，具有全局变量的特点，在任何位置都可以通过接口获取到那个唯一实例；

- **实现要点：**

  - 全局只有一个实例：static 特性，同时禁止用户自己声明并定义实例（把构造函数设为 private）；
  - 线程安全；
  - 禁止赋值和拷贝；
  - 用户通过接口获取实例：使用 static 类成员函数。

- **应用场景：**日志系统、数据库连接池、线程池等。

- **代码实现：**

  - **饿汉式：**在程序创建的时候就进行初始化,并且对象唯一；

  - **懒汉式：**需要时才创建于堆中，多线程情况下不能保证唯一性。

  - ```c++
    /* 最推荐的懒汉式单例(magic static)实现方法——局部静态变量  */
    // 依赖于C++11标准中的Magic Static特性：如果局部变量初始化时，并发同时进入声明语句，并发线程将会阻塞等待初始化结束。
    // 保证了并发线程在获取静态局部变量的时候一定是初始化过的，所以具有线程安全性。
    class Singleton
    {
    public:
        ~Singleton(){
            std::cout<<"destructor called!"<<std::endl;
        }
        Singleton(const Singleton&)=delete;
        Singleton& operator=(const Singleton&)=delete;
        static Singleton& get_instance(){
            static Singleton instance;
            return instance;
    
        }
    private:
        Singleton(){
            std::cout<<"constructor called!"<<std::endl;
        }
    };
    ```



### Linux

#### 1. 惊群效应

- **概念**：惊群现象就是**多进程（多线程）在同时阻塞等待同一个事件的时候（休眠状态），如果等待的这个事件发生，那么他就会唤醒等待的所有进程（或者线程），但是最终却只可能有一个进程（线程）对该事件进行处理**，而其他进程（线程）获取“控制权”失败，只能重新进入休眠状态，这种现象和性能浪费就叫做惊群。
- **性能浪费：**
  - 系统对用户进程/线程频繁地做无效的调度，上下文切换系统性能大打折扣；
  - 为了确保只有一个线程得到资源，用户必须对资源操作进行加锁保护，进一步加大了系统开销。
- **案例：**
  - **多个进程accept同一个socket，有连接来时，唤醒所有进程，但只有一个accept成功**。Linux内核2.6之后修复；
    - 在Linux 2.6版本中，维护了一个等待队列，非exclusive属性的进程会加在等待队列的前面，而exclusive属性的元素会加在等待队列的末尾。当子进程调用阻塞accept时，该进程会被打上WQ_FLAG_EXCLUSIVE标志位，从而成为exclusive进程被加到等待队列中。当有TCP连接请求到达时，该等待队列会被遍历，非exclusive属性的进程会被不断地唤醒，直到出现第一个exclusive属性的进程，该进程会被唤醒，同时遍历结束。
    - 因为阻塞在accept上的进程都是互斥的（都是打上WQ_FLAG_EXCLUSIVE标志位），所以TCP连接请求到达时只会有一个进程被唤醒，从而解决了惊群效应。
  - **多个进程epoll_wait同一个文件描述符，有事件发生时，唤醒所有进程，但只有一个epoll_wait成功**。Linux内核4.5之后可以通过传入EPOLLEXCLUSIVE标志位使子进程带上exclusive属性，即互斥属性，这样能够一定程度上缓解惊群效应，但如果想彻底避免惊群效应，还需要在应用层上做处理。
- **解决方法：**通常是**加进程间锁**，没太看明白。

#### 2. 僵尸进程

- **概念**：**僵尸进程就是运行结束之后还没有被父进程wait的子进程**，它们在运行结束之后PCB这些资源还没有被释放，等待父进程wait它们获得它们的状态。如果父进程不wait的话，僵尸进程多了，未被释放的资源就很多，这个时候系统性能就会受到影响。如果父进程早死了的话，子进程就会被托管到pid为1的进程，以前是init现在是systemd好像，它会定时wait掉所有死了的子进程；
- **解决方法：**
  - **单独一个线程wait子进程**；
  - **两个信号，SIGCHLD和SIGCLD，设置这两个信号的处理方式为忽略**，它们告诉内核，不关心子进程结束的状态，所以当子进程终止的时候直接释放所有资源就行。它们的区别是SIGCLD在安装完信号处理函数的时候还会检查是否已经存在结束的子进程，如果有就调用信号处理函数，而SIGCHLD不会，也就是可能会丢掉已经有子进程已经结束这个事实。



### 项目相关

#### 1. ProtoBuf

- protocol buffers 诞生之初也并不是为了传输数据存在的，只是为了解决服务器多版本协议兼容的问题。实质其实是发明了一个新的跨语言无歧义的 IDL (Interface description language)。只不过人们后来发现用它来传输数据也不错，才开始用 protocol buffers 。
- **序列化总结**：
  - **压缩数据（序列化工作量减少）**：
    - ProtoBuf 序列化采用 Varint、Zigzag 方法去压缩 int 型整数和带符号的整数，而对浮点型数字不做压缩(此处存在提升空间)；
    - 编码 `.proto` 文件时，会对 option 和 repeated 字段进行检查，若 optional 或 repeated 字段没有被设置字段值，那么该字段在序列化时的数据中是完全不存在的，即不进行序列化（少编码一个字段）。
  - **序列化速度快：**
    - 序列化的过程都是二进制的位移，速度非常快；
    - 数据都以 tag - length - value (或者 tag - value)的形式存在二进制数据流中。采用了 TLV 结构存储数据以后，也摆脱了 JSON 中的 {、}、; 、这些分隔符，没有这些分隔符也算是再一次减少了一部分数据量。
- **反序列化总结：**
  - Protocol Buffer 反序列化直接读取二进制字节数据流，反序列化就是 encode 的反过程，同样是一些二进制操作。反序列化的时候，通常只需要用到 length。tag 值只是用来标识类型的，Properties 的 setEncAndDec() 方法里面已经把每个类型对应的 decode 解码器初始化好了，所以反序列化的时候，tag 值可以直接跳过，从 length 开始处理。
  - XML 的解析过程就复杂一些。XML 需要从文件中读取出字符串，再转换为 XML 文档对象结构模型。之后，再从 XML 文档对象结构模型中读取指定节点的字符串，最后再将这个字符串转换成指定类型的变量。这个过程非常复杂，其中将 XML 文件转换为文档对象结构模型的过程通常需要完成词法文法分析等大量消耗 CPU 的复杂计算。
- **ProtoBuf优势总结：**
  - **Protobuf 采用了 Varint、Zigzag 大幅的压缩了整数类型，也没有 JSON 里面的 {、}、;、这些数据分隔符，有 option 字段标识的，没有数据的时候不会进行反序列化。这几个措施导致 pb 的数据量整体的就比 JSON 少很多**；
  - **Protobuf 采取的是 TLV 的形式，JSON 这些都是字符串的形式。字符串比对应基于数字的字段 tag 更耗时。Protobuf 在正文前有一个长度的标记，而 JSON 必须全文扫描无法跳过不需要的字段。**
- **ProtoBuf替换Json的原因总结：**
  -  相同数据，**传输的数据量比 JSON 小**，gzip 或者 7zip 压缩以后，**网络传输消耗较少**；
  - **不是自我描述的**，在缺少 `.proto` 文件以后，**有一定的加密性，数据传输过程中都是二进制流，并不是明文**；
  - 提供了一套工具，自动化生成代码也非常方便；
  - **具有向后兼容性**，改变了数据结构以后，对老的版本没有影响；
  - 原生完美兼容 RPC 调用。
- **注意**：**如果很少用到整型数字，浮点型数字，全部都是字符串数据，那么 JSON 和 protocol buffers 性能不会差太多。纯前端之间交互的话，选择 JSON 或者 protocol buffers 差别不是很大。**

#### 2. ZeroMQ

- **概念**：
  - ZeroMQ是一个**基于消息队列的多线程网络库**，其对套接字类型、连接处理、帧、甚至路由的底层细节进行抽象，提供跨越多种传输协议的套接字。
  - ZMQ不是单独的服务，而是一个嵌入式库，它封装了网络通信的功能，向上层提供简洁的API，应用程序通过加载库文件，调用API函数来实现高性能网络通信。
- **优点**：
  - 仅仅提供24个API接口，风格类似于BSD Socket；
  - 处理了网络异常，包括连接异常中断、重连等；
  - 改变TCP基于字节流收发数据的方式，处理了粘包、半包等问题，以msg为单位收发数据，结合Protocol Buffers，可以对应用层彻底屏蔽网络通信层；
  - 对大数据通过SENDMORE/RECVMORE提供分包收发机制；
  - 通过线程间数据流动来保证同一时刻任何数据都只会被一个线程持有，以此实现多线程的“去锁化”；
  - 通过高水位HWM来控制流量，用交换SWAP来转储内存数据，弥补HWM丢失数据的缺陷；
  - 服务器端和客户端的启动没有先后顺序。
- **架构**：
  - **I/O线程**：ZMQ根据用户调用zmq_init函数时传入的参数，创建对应数量的I/O线程。每个I/O线程都有与之绑定的Poller，Poller采用经典的Reactor模式实现；
    - Poller根据不同操作系统平台使用不同的网络I/O模型（select、poll、epoll、devpoll、kequeue等），所有的I/O操作都是异步的，线程不会被阻塞；
    - 主线程与I/O线程通过Mail Box传递消息来进行通信。
  - ![ZMQ架构图](/Users/apple/Documents/work2022/hq/面经图片/ZMQ架构图.png)
    - Server：在主线程创建zmq_listener，通过Mail Box发消息的形式将其绑定到I/O线程，I/O线程把zmq_listener添加到Poller中用以侦听读事件；
    - Client：在主线程中创建zmq_connecter，通过Mail Box发消息的形式将其绑定到I/O线程，I/O线程把zmq_connecter添加到Poller中用以侦听写事件；
    - Client与Server第一次通信时，会创建zmq_init来发送identity，用以进行认证。认证结束后，双方会为此次连接创建Session，以后双方就通过Session进行通信；
    - 每个Session都会关联到相应的读/写管道， 主线程收发消息只是分别从管道中读/写数据。Session并不实际跟kernel交换I/O数据，而是通过plugin到Session中的Engine来与kernel交换I/O数据。
- **消息通信四种模型**：
  - **一对一结对模型（Exclusive-Pair）**，可以认为是一个TCP Connection，但是TCP Server只能接受一个连接。数据可以双向流动，这点不同于后面的请求回应模型；
  - **请求回应模型（Request-Reply）**，由Client发起请求，并由Server响应，跟一对一结对模型的区别在于可以有多个Client；
  - **发布订阅模型（Publish-Subscribe）**，Publish端单向分发数据，且不关心是否把全部信息发送给Subscribe端。如果Publish端开始发布信息时，Subscribe端尚未连接进来，则这些信息会被直接丢弃。Subscribe端只能接收，不能反馈，且在Subscribe端消费速度慢于Publish端的情况下，会在Subscribe端堆积数据；
  - **管道模型（Push-Pull）**，从 PUSH 端单向的向 PULL 端单向的推送数据流。如果有多个PULL端同时连接到PUSH端，则PUSH端会在内部做一个负载均衡，采用平均分配的算法，将所有消息均衡发布到PULL端上。与发布订阅模型相比，管道模型在没有消费者的情况下，发布的消息不会被消耗掉；在消费者能力不够的情况下，能够提供多消费者并行消费解决方案。该模型主要用于多任务并行。
- ZMQ提供进程内（inproc://）、进程间（ipc://）、机器间（tcp://）、广播（pgm://）等四种通信协议。



### 操作系统

#### 1. 线程进程

- **进程**是**资源分配**的独立单位；
- **线程**是**资源调度**的独立单位。

#### 2. 进程间通信方式

- **管道**：
  - 有名管道：一种半双工的通信方式，它允许无亲缘关系进程间的通信
    - 优点：可以实现任意关系的进程间的通信
    - 缺点：
      1. 长期存于系统中，使用不当容易出错
      2. 缓冲区有限
  - 无名管道：一种半双工的通信方式，只能在具有亲缘关系的进程间使用（父子进程）
    - 优点：简单方便
    - 缺点：
      1. 局限于单向通信
      2. 只能创建在它的进程以及其有亲缘关系的进程之间
      3. 缓冲区有限
- **信号量**：一个计数器，可以用来控制多个线程对共享资源的访问
  - 优点：可以同步进程
  - 缺点：信号量有限
- **信号**：一种比较复杂的通信方式，用于通知接收进程某个事件已经发生
- **消息队列**：是消息的链表，存放在内核中并由消息队列标识符标识
  - 优点：可以实现任意进程间的通信，并通过系统调用函数来实现消息发送和接收之间的同步，无需考虑同步问题，方便
  - 缺点：信息的复制需要额外消耗 CPU 的时间，不适宜于信息量大或操作频繁的场合
- **共享内存**：映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问
  - 优点：无须复制，快捷，信息量大
  - 缺点：
    1. 通信是通过将共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，因此进程间的读写操作的同步问题
    2. 利用内存缓冲区直接交换信息，内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，不方便网络通信
- **套接字**：可用于不同计算机间的进程通信
  - 优点：
    1. 传输数据为字节级，传输数据可自定义，数据量小效率高
    2. 传输数据时间短，性能高
    3. 适合于客户端和服务器端之间信息实时交互
    4. 可以加密,数据安全性强
  - 缺点：需对传输的数据进行解析，转化成应用级的数据。

#### 3. 死锁

- **概念**：多个并发进程因争夺系统资源而产生相互等待的现象；
- **原理**：当一组进程中的每个进程都在等待某个事件发生，而只有这组进程中的其他进程才能触发该事件，这就称这组进程发生了死锁。
  - **本质原因**：
    - 系统资源有限；
    - 进程推进顺序不合理。
- **死锁产生的四个必要条件**：
  - **互斥**： 某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结束；
  - **占有且等待**：一个进程本身占有资源（一种或多种），同时还有资源未得到满足，正在等待其他进程释放该资源；
  - **不可抢占**：别人已经占有了某项资源，你不能因为自己也需要该资源，就去把别人的资源抢过来；
  - **循环等待**： 存在一个进程链，使得每个进程都占有下一个进程所需的至少一种资源。
- **避免死锁的方法**：
  - **死锁预防**：产生死锁需要四个条件，那么，只要这四个条件中至少有一个条件得不到满足，就不可能发生死锁了。由于互斥条件是非共享资源所必须的，不仅不能改变，还应加以保证，所以，主要是破坏产生死锁的其他三个条件。
    - **破坏“占有且等待”条件**：所有的进程在开始运行之前，必须一次性地申请其在整个运行过程中所需要的全部资源；
    - **破坏“不可抢占”条件**：当一个已经持有了一些资源的进程在提出新的资源请求没有得到满足时，它必须释放已经保持的所有资源，待以后需要使用的时候再重新申请。这就意味着进程已占有的资源会被短暂地释放或者说是被抢占了。该种方法实现起来比较复杂，且代价也比较大；
    - **破坏“循环等待”条件**：可以通过定义资源类型的线性顺序来预防。
  - **避免死锁**：在使用前进行判断，只允许不会产生死锁的进程申请资源。
    - **银行家算法**：通过对进程需求、占有和系统拥有资源的实时统计，确保系统在分配给进程资源不会造成死锁才会给与分配。

